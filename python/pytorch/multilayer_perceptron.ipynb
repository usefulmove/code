{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## construct model\n"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# create GPU device (if available)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# instantiate the model\n",
        "model = MLPerceptron() # multi-layer perceptron model\n",
        "\n",
        "# move the model to the GPU (if available)\n",
        "model.to(device)\n",
        "\n",
        "summary(model, (1, 28 * 28))\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "c536f531-0343-44f0-aeb8-90aa8b5aef7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 128]         100,480\n",
            "            Linear-2               [-1, 1, 128]          16,512\n",
            "            Linear-3               [-1, 1, 128]          16,512\n",
            "            Linear-4                [-1, 1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.51\n",
            "Estimated Total Size (MB): 0.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model training"
      ],
      "metadata": {
        "id": "FlS55kuJYNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 30\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "training_size = int(0.8 * len(dataset))  # 80% for training\n",
        "validation_size = len(dataset) - training_size  # 20% for validation\n",
        "training_data, validation_data = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# define loss criterion and optimizer\n",
        "loss_criterion = nn.MSELoss() # mean squared error loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8) # stochaistic gradient descent\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    for inputs, labels in training_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    training_loss = training_loss / len(training_loader)\n",
        "\n",
        "    # validation loss\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            # move inputs and labels to GPU (if available)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "            outputs = model(inputs)\n",
        "            labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "    validation_loss = validation_loss / len(validation_loader)        \n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f} \\tvalidation loss: {:.6f}'.format(epoch+1, training_loss, validation_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXdB9qVrX9k6",
        "outputId": "aa183082-f7c0-416e-98ab-802443badaa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 \ttraining loss: 0.027748 \tvalidation loss: 0.013806\n",
            "epoch: 2 \ttraining loss: 0.012041 \tvalidation loss: 0.010986\n",
            "epoch: 3 \ttraining loss: 0.008984 \tvalidation loss: 0.009133\n",
            "epoch: 4 \ttraining loss: 0.007398 \tvalidation loss: 0.007954\n",
            "epoch: 5 \ttraining loss: 0.006374 \tvalidation loss: 0.007061\n",
            "epoch: 6 \ttraining loss: 0.005622 \tvalidation loss: 0.006847\n",
            "epoch: 7 \ttraining loss: 0.004975 \tvalidation loss: 0.005795\n",
            "epoch: 8 \ttraining loss: 0.004527 \tvalidation loss: 0.005775\n",
            "epoch: 9 \ttraining loss: 0.004095 \tvalidation loss: 0.005033\n",
            "epoch: 10 \ttraining loss: 0.003755 \tvalidation loss: 0.004957\n",
            "epoch: 11 \ttraining loss: 0.003472 \tvalidation loss: 0.004688\n",
            "epoch: 12 \ttraining loss: 0.003152 \tvalidation loss: 0.004642\n",
            "epoch: 13 \ttraining loss: 0.002926 \tvalidation loss: 0.004384\n",
            "epoch: 14 \ttraining loss: 0.002733 \tvalidation loss: 0.004186\n",
            "epoch: 15 \ttraining loss: 0.002542 \tvalidation loss: 0.004555\n",
            "epoch: 16 \ttraining loss: 0.002352 \tvalidation loss: 0.004209\n",
            "epoch: 17 \ttraining loss: 0.002174 \tvalidation loss: 0.003921\n",
            "epoch: 18 \ttraining loss: 0.002069 \tvalidation loss: 0.004185\n",
            "epoch: 19 \ttraining loss: 0.001903 \tvalidation loss: 0.004108\n",
            "epoch: 20 \ttraining loss: 0.001807 \tvalidation loss: 0.003899\n",
            "epoch: 21 \ttraining loss: 0.001689 \tvalidation loss: 0.004166\n",
            "epoch: 22 \ttraining loss: 0.001601 \tvalidation loss: 0.004104\n",
            "epoch: 23 \ttraining loss: 0.001511 \tvalidation loss: 0.003699\n",
            "epoch: 24 \ttraining loss: 0.001443 \tvalidation loss: 0.003591\n",
            "epoch: 25 \ttraining loss: 0.001322 \tvalidation loss: 0.003646\n",
            "epoch: 26 \ttraining loss: 0.001232 \tvalidation loss: 0.003753\n",
            "epoch: 27 \ttraining loss: 0.001175 \tvalidation loss: 0.003588\n",
            "epoch: 28 \ttraining loss: 0.001103 \tvalidation loss: 0.003470\n",
            "epoch: 29 \ttraining loss: 0.001027 \tvalidation loss: 0.003502\n",
            "epoch: 30 \ttraining loss: 0.000984 \tvalidation loss: 0.003649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "error_inputs = []\n",
        "error_labels = []\n",
        "error_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # store inputs, labels, and predictions where predictions are incorrect\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != predicted[i]:\n",
        "                error_labels.append(label.item())\n",
        "                error_inputs.append(inputs[i])\n",
        "                error_predictions.append(predicted[i].item())\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}% ({:d} of {:d})'.format(accuracy, correct, total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "3c383943-e961-46ae-c9dc-80a5df68dd19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 97.88% (11745 of 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot example of a failed prediction"
      ],
      "metadata": {
        "id": "mRWY4ykeWvrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "ind = 0\n",
        "input = error_inputs[ind]\n",
        "label = error_labels[ind]\n",
        "prediction = error_predictions[ind]\n",
        "\n",
        "print(input.size())\n",
        "\n",
        "# unnormalize and reshape the image\n",
        "image_tensor = (input * 0.5 + 0.5).reshape((28, 28))\n",
        "\n",
        "# convert to PIL Image\n",
        "image = to_pil_image(image_tensor)\n",
        "\n",
        "print(f'model prediction: {prediction} \\tlabel: {label}')\n",
        "\n",
        "# display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hqORYRZdxbLv",
        "outputId": "b5612c86-3bbf-43b1-8886-528dec93829b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784])\n",
            "model prediction: 5 \tlabel: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
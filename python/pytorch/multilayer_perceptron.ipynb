{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## construct model\n"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# create GPU device (if available)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# instantiate the model\n",
        "model = MLPerceptron() # multi-layer perceptron model\n",
        "\n",
        "# move the model to the GPU (if available)\n",
        "model.to(device)\n",
        "\n",
        "summary(model, (1, 28 * 28))\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "c536f531-0343-44f0-aeb8-90aa8b5aef7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 128]         100,480\n",
            "            Linear-2               [-1, 1, 128]          16,512\n",
            "            Linear-3               [-1, 1, 128]          16,512\n",
            "            Linear-4                [-1, 1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.51\n",
            "Estimated Total Size (MB): 0.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model training"
      ],
      "metadata": {
        "id": "FlS55kuJYNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 30\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "training_size = int(0.8 * len(dataset))  # 80% for training\n",
        "validation_size = len(dataset) - training_size  # 20% for validation\n",
        "training_data, validation_data = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# define loss criterion and optimizer\n",
        "loss_criterion = nn.MSELoss() # mean squared error loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8) # stochaistic gradient descent\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    for inputs, labels in training_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    training_loss = training_loss / len(training_loader)\n",
        "\n",
        "    # validation loss\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            # move inputs and labels to GPU (if available)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "            outputs = model(inputs)\n",
        "            labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "    validation_loss = validation_loss / len(validation_loader)        \n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f} \\tvalidation loss: {:.6f}'.format(epoch+1, training_loss, validation_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXdB9qVrX9k6",
        "outputId": "974489a5-e26d-4d50-8c05-331faf9e0e31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 \ttraining loss: 0.001772 \tvalidation loss: 0.002003\n",
            "epoch: 2 \ttraining loss: 0.001627 \tvalidation loss: 0.001992\n",
            "epoch: 3 \ttraining loss: 0.001430 \tvalidation loss: 0.001569\n",
            "epoch: 4 \ttraining loss: 0.001337 \tvalidation loss: 0.001637\n",
            "epoch: 5 \ttraining loss: 0.001203 \tvalidation loss: 0.001717\n",
            "epoch: 6 \ttraining loss: 0.001063 \tvalidation loss: 0.001728\n",
            "epoch: 7 \ttraining loss: 0.001038 \tvalidation loss: 0.001711\n",
            "epoch: 8 \ttraining loss: 0.000930 \tvalidation loss: 0.001680\n",
            "epoch: 9 \ttraining loss: 0.000845 \tvalidation loss: 0.001585\n",
            "epoch: 10 \ttraining loss: 0.000775 \tvalidation loss: 0.002223\n",
            "epoch: 11 \ttraining loss: 0.000799 \tvalidation loss: 0.001642\n",
            "epoch: 12 \ttraining loss: 0.000708 \tvalidation loss: 0.001723\n",
            "epoch: 13 \ttraining loss: 0.000662 \tvalidation loss: 0.001673\n",
            "epoch: 14 \ttraining loss: 0.000634 \tvalidation loss: 0.001649\n",
            "epoch: 15 \ttraining loss: 0.000578 \tvalidation loss: 0.001703\n",
            "epoch: 16 \ttraining loss: 0.000546 \tvalidation loss: 0.001516\n",
            "epoch: 17 \ttraining loss: 0.000500 \tvalidation loss: 0.001691\n",
            "epoch: 18 \ttraining loss: 0.000482 \tvalidation loss: 0.001584\n",
            "epoch: 19 \ttraining loss: 0.000452 \tvalidation loss: 0.001674\n",
            "epoch: 20 \ttraining loss: 0.000439 \tvalidation loss: 0.001612\n",
            "epoch: 21 \ttraining loss: 0.000409 \tvalidation loss: 0.001617\n",
            "epoch: 22 \ttraining loss: 0.000390 \tvalidation loss: 0.001583\n",
            "epoch: 23 \ttraining loss: 0.000378 \tvalidation loss: 0.001572\n",
            "epoch: 24 \ttraining loss: 0.000366 \tvalidation loss: 0.001694\n",
            "epoch: 25 \ttraining loss: 0.000347 \tvalidation loss: 0.001586\n",
            "epoch: 26 \ttraining loss: 0.000340 \tvalidation loss: 0.001646\n",
            "epoch: 27 \ttraining loss: 0.000319 \tvalidation loss: 0.001623\n",
            "epoch: 28 \ttraining loss: 0.000300 \tvalidation loss: 0.001613\n",
            "epoch: 29 \ttraining loss: 0.000296 \tvalidation loss: 0.001594\n",
            "epoch: 30 \ttraining loss: 0.000280 \tvalidation loss: 0.001583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "error_inputs = []\n",
        "error_labels = []\n",
        "error_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # store inputs, labels, and predictions where predictions are incorrect\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != predicted[i]:\n",
        "                error_labels.append(label.item())\n",
        "                error_inputs.append(inputs[i])\n",
        "                error_predictions.append(predicted[i].item())\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}% ({:d} of {:d})'.format(accuracy, correct, total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "4fee4e87-647c-46dd-b9b8-7cc709ba2f88"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 99.18% (11902 of 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot example of a failed prediction"
      ],
      "metadata": {
        "id": "mRWY4ykeWvrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "ind = 0\n",
        "input = error_inputs[ind]\n",
        "label = error_labels[ind]\n",
        "prediction = error_predictions[ind]\n",
        "\n",
        "print(input.size())\n",
        "\n",
        "# unnormalize and reshape the image\n",
        "image_tensor = (input * 0.5 + 0.5).reshape((28, 28))\n",
        "\n",
        "# convert to PIL Image\n",
        "image = to_pil_image(image_tensor)\n",
        "\n",
        "print(f'model prediction: {prediction} \\tlabel: {label}')\n",
        "\n",
        "# display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hqORYRZdxbLv",
        "outputId": "f4bd2a11-5b4a-405d-d588-0798d7803d3d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784])\n",
            "model prediction: 9 \tlabel: 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save the model weights and biases"
      ],
      "metadata": {
        "id": "34j18Ykp70OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, \"/content/gdrive/My Drive/model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRe0msGk1CJy",
        "outputId": "3743e132-2b5c-42b8-bb91-91e4f5cb5fd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    }
  ]
}
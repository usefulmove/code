{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "construct and train model -\n",
        "multi-layer perceptron neural network model implementation on MNIST data"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "valid_size = len(dataset) - train_size  # 20% for validation\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# instantiate the model, loss criterion, and optimizer\n",
        "model = MLPerceptron()\n",
        "loss_criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 50\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f}'.format(epoch+1, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "769a13bc-f468-4848-e721-3b3321b8e855"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPerceptron(\n",
            "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (layer4): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "epoch: 1 \ttraining loss: 0.027897\n",
            "epoch: 2 \ttraining loss: 0.011972\n",
            "epoch: 3 \ttraining loss: 0.009035\n",
            "epoch: 4 \ttraining loss: 0.007542\n",
            "epoch: 5 \ttraining loss: 0.006481\n",
            "epoch: 6 \ttraining loss: 0.005592\n",
            "epoch: 7 \ttraining loss: 0.005077\n",
            "epoch: 8 \ttraining loss: 0.004473\n",
            "epoch: 9 \ttraining loss: 0.004135\n",
            "epoch: 10 \ttraining loss: 0.003778\n",
            "epoch: 11 \ttraining loss: 0.003496\n",
            "epoch: 12 \ttraining loss: 0.003235\n",
            "epoch: 13 \ttraining loss: 0.002951\n",
            "epoch: 14 \ttraining loss: 0.002765\n",
            "epoch: 15 \ttraining loss: 0.002563\n",
            "epoch: 16 \ttraining loss: 0.002414\n",
            "epoch: 17 \ttraining loss: 0.002231\n",
            "epoch: 18 \ttraining loss: 0.002134\n",
            "epoch: 19 \ttraining loss: 0.001969\n",
            "epoch: 20 \ttraining loss: 0.001833\n",
            "epoch: 21 \ttraining loss: 0.001696\n",
            "epoch: 22 \ttraining loss: 0.001633\n",
            "epoch: 23 \ttraining loss: 0.001558\n",
            "epoch: 24 \ttraining loss: 0.001390\n",
            "epoch: 25 \ttraining loss: 0.001359\n",
            "epoch: 26 \ttraining loss: 0.001340\n",
            "epoch: 27 \ttraining loss: 0.001194\n",
            "epoch: 28 \ttraining loss: 0.001139\n",
            "epoch: 29 \ttraining loss: 0.001068\n",
            "epoch: 30 \ttraining loss: 0.001030\n",
            "epoch: 31 \ttraining loss: 0.000953\n",
            "epoch: 32 \ttraining loss: 0.000866\n",
            "epoch: 33 \ttraining loss: 0.000811\n",
            "epoch: 34 \ttraining loss: 0.000817\n",
            "epoch: 35 \ttraining loss: 0.000747\n",
            "epoch: 36 \ttraining loss: 0.000697\n",
            "epoch: 37 \ttraining loss: 0.000653\n",
            "epoch: 38 \ttraining loss: 0.000620\n",
            "epoch: 39 \ttraining loss: 0.000574\n",
            "epoch: 40 \ttraining loss: 0.000576\n",
            "epoch: 41 \ttraining loss: 0.000528\n",
            "epoch: 42 \ttraining loss: 0.000519\n",
            "epoch: 43 \ttraining loss: 0.000488\n",
            "epoch: 44 \ttraining loss: 0.000450\n",
            "epoch: 45 \ttraining loss: 0.000440\n",
            "epoch: 46 \ttraining loss: 0.000410\n",
            "epoch: 47 \ttraining loss: 0.000397\n",
            "epoch: 48 \ttraining loss: 0.000374\n",
            "epoch: 49 \ttraining loss: 0.000368\n",
            "epoch: 50 \ttraining loss: 0.000338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "3f189cad-6f38-46c2-a163-b20603f509a0"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 98.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "ind = 46\n",
        "input, label = valid_dataset[ind]\n",
        "\n",
        "# ensure the tensor is of correct shape\n",
        "input_tensor = input.view(1, -1)  # reshape to [1, 784] if it's not already\n",
        "\n",
        "# run the model\n",
        "output_tensor = model(input_tensor)\n",
        "\n",
        "_, max_index = torch.max(output_tensor, dim=1)\n",
        "print(f'model prediction: {max_index.item()}   label: {label}')\n",
        "\n",
        "# unnormalize the image\n",
        "unnorm_tensor = input * 0.5 + 0.5\n",
        "\n",
        "# convert to PIL Image\n",
        "img = to_pil_image(unnorm_tensor)\n",
        "\n",
        "# display the image\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hqORYRZdxbLv",
        "outputId": "735dac11-6766-46bc-b488-cffb77fa208f"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n",
            "model prediction: 2   label: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZhklEQVR4nO3db0yV9/3/8dfxD0fbwnGIcKCiRW11qcoyp4y0RZxEZYvx3w3tekMXo9FhM2VtF5dVcFvC5pKu6cLsbiy6ZtV2JlNTb5BYFMw2tJFqjNlGxLCJEXA14RzEggY+vxv+er49CtKD5/A+5/B8JJ9EznVdnHevXfG5wzlcepxzTgAAjLAx1gMAAEYnAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEyMsx7gQf39/bpx44ZSU1Pl8XisxwEARMg5p66uLuXk5GjMmMFf58RdgG7cuKHc3FzrMQAAj6m1tVVTp04ddHvc/QguNTXVegQAQBQM9fd5zAJUXV2tZ555RhMmTFBBQYE++eSTr3QcP3YDgOQw1N/nMQnQhx9+qPLyclVUVOjTTz9Vfn6+li9frps3b8bi6QAAicjFwKJFi1xZWVno676+PpeTk+OqqqqGPDYQCDhJLBaLxUrwFQgEHvn3fdRfAd29e1eNjY0qKSkJPTZmzBiVlJSooaHhof17e3sVDAbDFgAg+UU9QJ999pn6+vqUlZUV9nhWVpba29sf2r+qqko+ny+0+AQcAIwO5p+C2717twKBQGi1trZajwQAGAFR/z2gjIwMjR07Vh0dHWGPd3R0yO/3P7S/1+uV1+uN9hgAgDgX9VdAKSkpWrBggWpra0OP9ff3q7a2VoWFhdF+OgBAgorJnRDKy8u1ceNGfetb39KiRYv09ttvq7u7Wz/4wQ9i8XQAgAQUkwCtX79e//vf/7Rnzx61t7frG9/4hmpqah76YAIAYPTyOOec9RBfFgwG5fP5rMcAADymQCCgtLS0QbebfwoOADA6ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIlx1gMA8aSysjLiYxYvXhzxMcXFxREfs3fv3oiPqauri/iYxzkOiASvgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEx7nnLMe4suCwaB8Pp/1GEhww7mpqCRVVFREd5AENZwbnw73nCN5BQIBpaWlDbqdV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRoqkdPr06WEdV1xcHN1B8EhLliyJ+Ji6urroD4KY4GakAIC4RIAAACaiHqDKykp5PJ6wNWfOnGg/DQAgwY2LxTd9/vnn9fHHH//fk4yLydMAABJYTMowbtw4+f3+WHxrAECSiMl7QFeuXFFOTo5mzJihV155RdeuXRt0397eXgWDwbAFAEh+UQ9QQUGBDh48qJqaGu3fv18tLS166aWX1NXVNeD+VVVV8vl8oZWbmxvtkQAAcSjmvwfU2dmp6dOn66233tLmzZsf2t7b26ve3t7Q18FgkAjhsfF7QImB3wNKbkP9HlDMPx0wadIkPffcc2pubh5wu9frldfrjfUYAIA4E/PfA7p9+7auXr2q7OzsWD8VACCBRD1Ar732murr6/Wf//xH//jHP7RmzRqNHTtWL7/8crSfCgCQwKL+I7jr16/r5Zdf1q1btzRlyhS9+OKLOnv2rKZMmRLtpwIAJDBuRoqkNNwPE4zUhxCG80Z6RUVFxMck44cq+OBC4uBmpACAuESAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmOBmpEASG+7NSIf7L8rGK4/HYz3CqMTNSAEAcYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBs2gIdUVlZGfExFRUX0B4kS7oZtg7thAwDiEgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYpz1AABip7i4eFjHLV68OLqDAAPgFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQJJbLg3Ix3ucSNh79691iMgSngFBAAwQYAAACYiDtCZM2e0cuVK5eTkyOPx6NixY2HbnXPas2ePsrOzNXHiRJWUlOjKlSvRmhcAkCQiDlB3d7fy8/NVXV094PZ9+/bpnXfe0bvvvqtz587pySef1PLly9XT0/PYwwIAkkfEH0IoLS1VaWnpgNucc3r77bf1s5/9TKtWrZIkvffee8rKytKxY8e0YcOGx5sWAJA0ovoeUEtLi9rb21VSUhJ6zOfzqaCgQA0NDQMe09vbq2AwGLYAAMkvqgFqb2+XJGVlZYU9npWVFdr2oKqqKvl8vtDKzc2N5kgAgDhl/im43bt3KxAIhFZra6v1SACAERDVAPn9fklSR0dH2OMdHR2hbQ/yer1KS0sLWwCA5BfVAOXl5cnv96u2tjb0WDAY1Llz51RYWBjNpwIAJLiIPwV3+/ZtNTc3h75uaWnRxYsXlZ6ermnTpmnnzp365S9/qWeffVZ5eXl68803lZOTo9WrV0dzbgBAgos4QOfPn9eSJUtCX5eXl0uSNm7cqIMHD+qNN95Qd3e3tm7dqs7OTr344ouqqanRhAkTojc1ACDheZxzznqILwsGg/L5fNZjAEmhsrJyWMdVVFREd5BBDOfGosP9b8LICwQCj3xf3/xTcACA0YkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmIv7nGAAgWurq6qxHgCFeAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKQAz3Ix0dOMVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAi4gCdOXNGK1euVE5Ojjwej44dOxa2fdOmTfJ4PGFrxYoV0ZoXAJAkIg5Qd3e38vPzVV1dPeg+K1asUFtbW2gdPnz4sYYEACSfcZEeUFpaqtLS0kfu4/V65ff7hz0UACD5xeQ9oLq6OmVmZmr27Nnavn27bt26Nei+vb29CgaDYQsAkPyiHqAVK1bovffeU21trX7961+rvr5epaWl6uvrG3D/qqoq+Xy+0MrNzY32SACAOBTxj+CGsmHDhtCf582bp/nz52vmzJmqq6vT0qVLH9p/9+7dKi8vD30dDAaJEACMAjH/GPaMGTOUkZGh5ubmAbd7vV6lpaWFLQBA8ot5gK5fv65bt24pOzs71k8FAEggEf8I7vbt22GvZlpaWnTx4kWlp6crPT1de/fu1bp16+T3+3X16lW98cYbmjVrlpYvXx7VwQEAiS3iAJ0/f15LliwJff3F+zcbN27U/v37denSJf3pT39SZ2encnJytGzZMv3iF7+Q1+uN3tQAgITncc456yG+LBgMyufzWY8BxJ3KysqIj6moqIj+IFHk8XisR0AMBQKBR76vz73gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLq/yQ3gKEl452t6+rqrEdAguEVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgwuOcc9ZDfFkwGJTP57MeA6PUcG4Sunjx4oiPKS4ujviYeOfxeKxHQJwJBAJKS0sbdDuvgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE+OsBxgthnPzyYqKihF5nrq6uoiPkaT6+vqIj+HGnYlhyZIl1iNgFOAVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRjpDh3FBzpG7COdzn4Sah8W+4NxUd7g1qgUjwCggAYIIAAQBMRBSgqqoqLVy4UKmpqcrMzNTq1avV1NQUtk9PT4/Kyso0efJkPfXUU1q3bp06OjqiOjQAIPFFFKD6+nqVlZXp7NmzOnnypO7du6dly5apu7s7tM+uXbv00Ucf6ciRI6qvr9eNGze0du3aqA8OAEhsEX0IoaamJuzrgwcPKjMzU42NjSoqKlIgENAf//hHHTp0SN/5znckSQcOHNDXv/51nT17Vt/+9rejNzkAIKE91ntAgUBAkpSeni5Jamxs1L1791RSUhLaZ86cOZo2bZoaGhoG/B69vb0KBoNhCwCQ/IYdoP7+fu3cuVMvvPCC5s6dK0lqb29XSkqKJk2aFLZvVlaW2tvbB/w+VVVV8vl8oZWbmzvckQAACWTYASorK9Ply5f1wQcfPNYAu3fvViAQCK3W1tbH+n4AgMQwrF9E3bFjh06cOKEzZ85o6tSpocf9fr/u3r2rzs7OsFdBHR0d8vv9A34vr9crr9c7nDEAAAksoldAzjnt2LFDR48e1alTp5SXlxe2fcGCBRo/frxqa2tDjzU1NenatWsqLCyMzsQAgKQQ0SugsrIyHTp0SMePH1dqamrofR2fz6eJEyfK5/Np8+bNKi8vV3p6utLS0vTqq6+qsLCQT8ABAMJEFKD9+/dLevgeYAcOHNCmTZskSb/97W81ZswYrVu3Tr29vVq+fLl+//vfR2VYAEDyiChAzrkh95kwYYKqq6tVXV097KGARDKcG3fW19dHfExlZWXExwDxjHvBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwITHfZVbXI+gYDAon89nPUZcePCfvYjVMRUVFREfM5JG6m7Tw32u4RwDjAaBQEBpaWmDbucVEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABggpuRAgBigpuRAgDiEgECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAiogBVVVVp4cKFSk1NVWZmplavXq2mpqawfYqLi+XxeMLWtm3bojo0ACDxRRSg+vp6lZWV6ezZszp58qTu3bunZcuWqbu7O2y/LVu2qK2tLbT27dsX1aEBAIlvXCQ719TUhH198OBBZWZmqrGxUUVFRaHHn3jiCfn9/uhMCABISo/1HlAgEJAkpaenhz3+/vvvKyMjQ3PnztXu3bt1586dQb9Hb2+vgsFg2AIAjAJumPr6+tz3vvc998ILL4Q9/oc//MHV1NS4S5cuuT//+c/u6aefdmvWrBn0+1RUVDhJLBaLxUqyFQgEHtmRYQdo27Ztbvr06a61tfWR+9XW1jpJrrm5ecDtPT09LhAIhFZra6v5SWOxWCzW46+hAhTRe0Bf2LFjh06cOKEzZ85o6tSpj9y3oKBAktTc3KyZM2c+tN3r9crr9Q5nDABAAosoQM45vfrqqzp69Kjq6uqUl5c35DEXL16UJGVnZw9rQABAcoooQGVlZTp06JCOHz+u1NRUtbe3S5J8Pp8mTpyoq1ev6tChQ/rud7+ryZMn69KlS9q1a5eKioo0f/78mPwHAAASVCTv+2iQn/MdOHDAOefctWvXXFFRkUtPT3der9fNmjXLvf7660P+HPDLAoGA+c8tWSwWi/X4a6i/+z3/PyxxIxgMyufzWY8BAHhMgUBAaWlpg27nXnAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABNxFyDnnPUIAIAoGOrv87gLUFdXl/UIAIAoGOrvc4+Ls5cc/f39unHjhlJTU+XxeMK2BYNB5ebmqrW1VWlpaUYT2uM83Md5uI/zcB/n4b54OA/OOXV1dSknJ0djxgz+OmfcCM70lYwZM0ZTp0595D5paWmj+gL7AufhPs7DfZyH+zgP91mfB5/PN+Q+cfcjOADA6ECAAAAmEipAXq9XFRUV8nq91qOY4jzcx3m4j/NwH+fhvkQ6D3H3IQQAwOiQUK+AAADJgwABAEwQIACACQIEADCRMAGqrq7WM888owkTJqigoECffPKJ9UgjrrKyUh6PJ2zNmTPHeqyYO3PmjFauXKmcnBx5PB4dO3YsbLtzTnv27FF2drYmTpyokpISXblyxWbYGBrqPGzatOmh62PFihU2w8ZIVVWVFi5cqNTUVGVmZmr16tVqamoK26enp0dlZWWaPHmynnrqKa1bt04dHR1GE8fGVzkPxcXFD10P27ZtM5p4YAkRoA8//FDl5eWqqKjQp59+qvz8fC1fvlw3b960Hm3EPf/882prawutv/3tb9YjxVx3d7fy8/NVXV094PZ9+/bpnXfe0bvvvqtz587pySef1PLly9XT0zPCk8bWUOdBklasWBF2fRw+fHgEJ4y9+vp6lZWV6ezZszp58qTu3bunZcuWqbu7O7TPrl279NFHH+nIkSOqr6/XjRs3tHbtWsOpo++rnAdJ2rJlS9j1sG/fPqOJB+ESwKJFi1xZWVno676+PpeTk+OqqqoMpxp5FRUVLj8/33oMU5Lc0aNHQ1/39/c7v9/vfvOb34Qe6+zsdF6v1x0+fNhgwpHx4HlwzrmNGze6VatWmcxj5ebNm06Sq6+vd87d/99+/Pjx7siRI6F9/vWvfzlJrqGhwWrMmHvwPDjn3OLFi92PfvQju6G+grh/BXT37l01NjaqpKQk9NiYMWNUUlKihoYGw8lsXLlyRTk5OZoxY4ZeeeUVXbt2zXokUy0tLWpvbw+7Pnw+nwoKCkbl9VFXV6fMzEzNnj1b27dv161bt6xHiqlAICBJSk9PlyQ1Njbq3r17YdfDnDlzNG3atKS+Hh48D194//33lZGRoblz52r37t26c+eOxXiDirubkT7os88+U19fn7KyssIez8rK0r///W+jqWwUFBTo4MGDmj17ttra2rR371699NJLunz5slJTU63HM9He3i5JA14fX2wbLVasWKG1a9cqLy9PV69e1U9/+lOVlpaqoaFBY8eOtR4v6vr7+7Vz50698MILmjt3rqT710NKSoomTZoUtm8yXw8DnQdJ+v73v6/p06crJydHly5d0k9+8hM1NTXpr3/9q+G04eI+QPg/paWloT/Pnz9fBQUFmj59uv7yl79o8+bNhpMhHmzYsCH053nz5mn+/PmaOXOm6urqtHTpUsPJYqOsrEyXL18eFe+DPspg52Hr1q2hP8+bN0/Z2dlaunSprl69qpkzZ470mAOK+x/BZWRkaOzYsQ99iqWjo0N+v99oqvgwadIkPffcc2pubrYexcwX1wDXx8NmzJihjIyMpLw+duzYoRMnTuj06dNh/3yL3+/X3bt31dnZGbZ/sl4Pg52HgRQUFEhSXF0PcR+glJQULViwQLW1taHH+vv7VVtbq8LCQsPJ7N2+fVtXr15Vdna29Shm8vLy5Pf7w66PYDCoc+fOjfrr4/r167p161ZSXR/OOe3YsUNHjx7VqVOnlJeXF7Z9wYIFGj9+fNj10NTUpGvXriXV9TDUeRjIxYsXJSm+rgfrT0F8FR988IHzer3u4MGD7p///KfbunWrmzRpkmtvb7cebUT9+Mc/dnV1da6lpcX9/e9/dyUlJS4jI8PdvHnTerSY6urqchcuXHAXLlxwktxbb73lLly44P773/8655z71a9+5SZNmuSOHz/uLl265FatWuXy8vLc559/bjx5dD3qPHR1dbnXXnvNNTQ0uJaWFvfxxx+7b37zm+7ZZ591PT091qNHzfbt253P53N1dXWura0ttO7cuRPaZ9u2bW7atGnu1KlT7vz5866wsNAVFhYaTh19Q52H5uZm9/Of/9ydP3/etbS0uOPHj7sZM2a4oqIi48nDJUSAnHPud7/7nZs2bZpLSUlxixYtcmfPnrUeacStX7/eZWdnu5SUFPf000+79evXu+bmZuuxYu706dNO0kNr48aNzrn7H8V+8803XVZWlvN6vW7p0qWuqanJdugYeNR5uHPnjlu2bJmbMmWKGz9+vJs+fbrbsmVL0v2ftIH++yW5AwcOhPb5/PPP3Q9/+EP3ta99zT3xxBNuzZo1rq2tzW7oGBjqPFy7ds0VFRW59PR05/V63axZs9zrr7/uAoGA7eAP4J9jAACYiPv3gAAAyYkAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMPH/ABiGao5L+7+eAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
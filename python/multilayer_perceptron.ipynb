{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "construct and train model -\n",
        "multi-layer perceptron neural network model implementation on MNIST data"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "training_size = int(0.8 * len(dataset))  # 80% for training\n",
        "validation_size = len(dataset) - training_size  # 20% for validation\n",
        "training_data, validation_data = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# instantiate the model, loss criterion, and optimizer\n",
        "model = MLPerceptron() # multi-layer perceptron model\n",
        "loss_criterion = nn.MSELoss() # mean squared error loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8) # stochaistic gradient descent\n",
        "\n",
        "print(model)\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 30\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    for inputs, labels in training_loader:\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    training_loss = training_loss / len(training_loader)\n",
        "\n",
        "    # validation loss\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "            outputs = model(inputs)\n",
        "            labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "    validation_loss = validation_loss / len(validation_loader)        \n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f} \\tvalidation loss: {:.6f}'.format(epoch+1, training_loss, validation_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "bc40f18b-7584-4eb2-d8df-10411005a739"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPerceptron(\n",
            "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (layer4): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "epoch: 1 \ttraining loss: 0.027741 \tvalidation loss: 0.013113\n",
            "epoch: 2 \ttraining loss: 0.012030 \tvalidation loss: 0.009290\n",
            "epoch: 3 \ttraining loss: 0.008943 \tvalidation loss: 0.007780\n",
            "epoch: 4 \ttraining loss: 0.007466 \tvalidation loss: 0.007016\n",
            "epoch: 5 \ttraining loss: 0.006309 \tvalidation loss: 0.006315\n",
            "epoch: 6 \ttraining loss: 0.005600 \tvalidation loss: 0.005779\n",
            "epoch: 7 \ttraining loss: 0.005042 \tvalidation loss: 0.005609\n",
            "epoch: 8 \ttraining loss: 0.004511 \tvalidation loss: 0.004918\n",
            "epoch: 9 \ttraining loss: 0.004115 \tvalidation loss: 0.004672\n",
            "epoch: 10 \ttraining loss: 0.003755 \tvalidation loss: 0.004336\n",
            "epoch: 11 \ttraining loss: 0.003452 \tvalidation loss: 0.005070\n",
            "epoch: 12 \ttraining loss: 0.003219 \tvalidation loss: 0.004526\n",
            "epoch: 13 \ttraining loss: 0.002917 \tvalidation loss: 0.004925\n",
            "epoch: 14 \ttraining loss: 0.002754 \tvalidation loss: 0.004043\n",
            "epoch: 15 \ttraining loss: 0.002577 \tvalidation loss: 0.003943\n",
            "epoch: 16 \ttraining loss: 0.002390 \tvalidation loss: 0.003939\n",
            "epoch: 17 \ttraining loss: 0.002214 \tvalidation loss: 0.003867\n",
            "epoch: 18 \ttraining loss: 0.002048 \tvalidation loss: 0.004094\n",
            "epoch: 19 \ttraining loss: 0.001954 \tvalidation loss: 0.003647\n",
            "epoch: 20 \ttraining loss: 0.001831 \tvalidation loss: 0.003578\n",
            "epoch: 21 \ttraining loss: 0.001716 \tvalidation loss: 0.004315\n",
            "epoch: 22 \ttraining loss: 0.001576 \tvalidation loss: 0.003551\n",
            "epoch: 23 \ttraining loss: 0.001441 \tvalidation loss: 0.003978\n",
            "epoch: 24 \ttraining loss: 0.001408 \tvalidation loss: 0.003467\n",
            "epoch: 25 \ttraining loss: 0.001304 \tvalidation loss: 0.003513\n",
            "epoch: 26 \ttraining loss: 0.001242 \tvalidation loss: 0.003573\n",
            "epoch: 27 \ttraining loss: 0.001188 \tvalidation loss: 0.003465\n",
            "epoch: 28 \ttraining loss: 0.001085 \tvalidation loss: 0.003419\n",
            "epoch: 29 \ttraining loss: 0.001044 \tvalidation loss: 0.003427\n",
            "epoch: 30 \ttraining loss: 0.000975 \tvalidation loss: 0.003394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "error_inputs = []\n",
        "error_labels = []\n",
        "error_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # store inputs, labels, and predictions where predictions are incorrect\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != predicted[i]:\n",
        "                error_labels.append(label.item())\n",
        "                error_inputs.append(inputs[i])\n",
        "                error_predictions.append(predicted[i].item())\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "4b4d1948-2ff3-4cc6-fb45-4d8ef429c07a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 98.07%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "ind = 0\n",
        "input = error_inputs[ind]\n",
        "label = error_labels[ind]\n",
        "prediction = error_predictions[ind]\n",
        "\n",
        "print(input.size())\n",
        "\n",
        "# ensure the tensor is of correct shape\n",
        "input_tensor = input.view(1, -1)  # reshape to [1, 784] if it's not already\n",
        "\n",
        "# unnormalize the image\n",
        "unnorm_tensor = input * 0.5 + 0.5\n",
        "\n",
        "# convert to PIL Image\n",
        "img = to_pil_image(unnorm_tensor.reshape([28, 28]))\n",
        "\n",
        "print(f'model prediction: {prediction}   label: {label}')\n",
        "\n",
        "# display the image\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hqORYRZdxbLv",
        "outputId": "432978ab-c32b-4e86-f4be-e3fc2531ee7a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784])\n",
            "model prediction: 5   label: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
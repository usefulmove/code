{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "construct and train model -\n",
        "multi-layer perceptron neural network model implementation on MNIST data"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        self.layer1 = nn.Linear(784, 100)\n",
        "        self.layer2 = nn.Linear(100, 100)\n",
        "        self.layer3 = nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "valid_size = len(dataset) - train_size  # 20% for validation\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# instantiate the model, loss criterion, and optimizer\n",
        "model = MLPerceptron()\n",
        "loss_criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 50\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f}'.format(epoch+1, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "df8f19b2-d2ba-42a6-b524-dd04ff2d8a76"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPerceptron(\n",
            "  (layer1): Linear(in_features=784, out_features=100, bias=True)\n",
            "  (layer2): Linear(in_features=100, out_features=100, bias=True)\n",
            "  (layer3): Linear(in_features=100, out_features=10, bias=True)\n",
            ")\n",
            "epoch: 1 \ttraining loss: 0.028177\n",
            "epoch: 2 \ttraining loss: 0.014054\n",
            "epoch: 3 \ttraining loss: 0.011061\n",
            "epoch: 4 \ttraining loss: 0.009434\n",
            "epoch: 5 \ttraining loss: 0.008421\n",
            "epoch: 6 \ttraining loss: 0.007626\n",
            "epoch: 7 \ttraining loss: 0.007001\n",
            "epoch: 8 \ttraining loss: 0.006532\n",
            "epoch: 9 \ttraining loss: 0.006084\n",
            "epoch: 10 \ttraining loss: 0.005737\n",
            "epoch: 11 \ttraining loss: 0.005408\n",
            "epoch: 12 \ttraining loss: 0.005217\n",
            "epoch: 13 \ttraining loss: 0.004965\n",
            "epoch: 14 \ttraining loss: 0.004732\n",
            "epoch: 15 \ttraining loss: 0.004528\n",
            "epoch: 16 \ttraining loss: 0.004379\n",
            "epoch: 17 \ttraining loss: 0.004234\n",
            "epoch: 18 \ttraining loss: 0.004024\n",
            "epoch: 19 \ttraining loss: 0.003875\n",
            "epoch: 20 \ttraining loss: 0.003751\n",
            "epoch: 21 \ttraining loss: 0.003628\n",
            "epoch: 22 \ttraining loss: 0.003499\n",
            "epoch: 23 \ttraining loss: 0.003400\n",
            "epoch: 24 \ttraining loss: 0.003307\n",
            "epoch: 25 \ttraining loss: 0.003161\n",
            "epoch: 26 \ttraining loss: 0.003052\n",
            "epoch: 27 \ttraining loss: 0.002994\n",
            "epoch: 28 \ttraining loss: 0.002918\n",
            "epoch: 29 \ttraining loss: 0.002782\n",
            "epoch: 30 \ttraining loss: 0.002683\n",
            "epoch: 31 \ttraining loss: 0.002618\n",
            "epoch: 32 \ttraining loss: 0.002518\n",
            "epoch: 33 \ttraining loss: 0.002472\n",
            "epoch: 34 \ttraining loss: 0.002408\n",
            "epoch: 35 \ttraining loss: 0.002337\n",
            "epoch: 36 \ttraining loss: 0.002241\n",
            "epoch: 37 \ttraining loss: 0.002194\n",
            "epoch: 38 \ttraining loss: 0.002153\n",
            "epoch: 39 \ttraining loss: 0.002073\n",
            "epoch: 40 \ttraining loss: 0.002004\n",
            "epoch: 41 \ttraining loss: 0.001969\n",
            "epoch: 42 \ttraining loss: 0.001905\n",
            "epoch: 43 \ttraining loss: 0.001854\n",
            "epoch: 44 \ttraining loss: 0.001806\n",
            "epoch: 45 \ttraining loss: 0.001753\n",
            "epoch: 46 \ttraining loss: 0.001742\n",
            "epoch: 47 \ttraining loss: 0.001655\n",
            "epoch: 48 \ttraining loss: 0.001621\n",
            "epoch: 49 \ttraining loss: 0.001585\n",
            "epoch: 50 \ttraining loss: 0.001556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "2aaebe45-0c85-4053-e43e-a6a03a27432a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 97.28%\n"
          ]
        }
      ]
    }
  ]
}
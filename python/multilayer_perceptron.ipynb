{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "construct and train model -\n",
        "multi-layer perceptron neural network model implementation on MNIST data"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = self.layer3(x)\n",
        "        return x\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(dataset))  # 80% for training\n",
        "valid_size = len(dataset) - train_size  # 20% for validation\n",
        "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# instantiate the model, loss criterion, and optimizer\n",
        "model = MLPerceptron()\n",
        "loss_criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.8)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 100\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f}'.format(epoch+1, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "6ebd087f-d6ce-4973-c9f2-c347dd1bd0a3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPerceptron(\n",
            "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
            "  (layer3): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n",
            "epoch: 1 \ttraining loss: 0.027357\n",
            "epoch: 2 \ttraining loss: 0.013101\n",
            "epoch: 3 \ttraining loss: 0.010187\n",
            "epoch: 4 \ttraining loss: 0.008643\n",
            "epoch: 5 \ttraining loss: 0.007635\n",
            "epoch: 6 \ttraining loss: 0.006886\n",
            "epoch: 7 \ttraining loss: 0.006331\n",
            "epoch: 8 \ttraining loss: 0.005852\n",
            "epoch: 9 \ttraining loss: 0.005450\n",
            "epoch: 10 \ttraining loss: 0.005123\n",
            "epoch: 11 \ttraining loss: 0.004812\n",
            "epoch: 12 \ttraining loss: 0.004565\n",
            "epoch: 13 \ttraining loss: 0.004350\n",
            "epoch: 14 \ttraining loss: 0.004189\n",
            "epoch: 15 \ttraining loss: 0.003924\n",
            "epoch: 16 \ttraining loss: 0.003790\n",
            "epoch: 17 \ttraining loss: 0.003628\n",
            "epoch: 18 \ttraining loss: 0.003454\n",
            "epoch: 19 \ttraining loss: 0.003315\n",
            "epoch: 20 \ttraining loss: 0.003202\n",
            "epoch: 21 \ttraining loss: 0.003060\n",
            "epoch: 22 \ttraining loss: 0.002965\n",
            "epoch: 23 \ttraining loss: 0.002845\n",
            "epoch: 24 \ttraining loss: 0.002732\n",
            "epoch: 25 \ttraining loss: 0.002634\n",
            "epoch: 26 \ttraining loss: 0.002536\n",
            "epoch: 27 \ttraining loss: 0.002452\n",
            "epoch: 28 \ttraining loss: 0.002355\n",
            "epoch: 29 \ttraining loss: 0.002280\n",
            "epoch: 30 \ttraining loss: 0.002213\n",
            "epoch: 31 \ttraining loss: 0.002122\n",
            "epoch: 32 \ttraining loss: 0.002097\n",
            "epoch: 33 \ttraining loss: 0.002013\n",
            "epoch: 34 \ttraining loss: 0.001946\n",
            "epoch: 35 \ttraining loss: 0.001866\n",
            "epoch: 36 \ttraining loss: 0.001829\n",
            "epoch: 37 \ttraining loss: 0.001739\n",
            "epoch: 38 \ttraining loss: 0.001693\n",
            "epoch: 39 \ttraining loss: 0.001672\n",
            "epoch: 40 \ttraining loss: 0.001591\n",
            "epoch: 41 \ttraining loss: 0.001553\n",
            "epoch: 42 \ttraining loss: 0.001548\n",
            "epoch: 43 \ttraining loss: 0.001447\n",
            "epoch: 44 \ttraining loss: 0.001420\n",
            "epoch: 45 \ttraining loss: 0.001365\n",
            "epoch: 46 \ttraining loss: 0.001330\n",
            "epoch: 47 \ttraining loss: 0.001296\n",
            "epoch: 48 \ttraining loss: 0.001260\n",
            "epoch: 49 \ttraining loss: 0.001209\n",
            "epoch: 50 \ttraining loss: 0.001173\n",
            "epoch: 51 \ttraining loss: 0.001156\n",
            "epoch: 52 \ttraining loss: 0.001137\n",
            "epoch: 53 \ttraining loss: 0.001093\n",
            "epoch: 54 \ttraining loss: 0.001044\n",
            "epoch: 55 \ttraining loss: 0.001035\n",
            "epoch: 56 \ttraining loss: 0.001011\n",
            "epoch: 57 \ttraining loss: 0.000989\n",
            "epoch: 58 \ttraining loss: 0.000932\n",
            "epoch: 59 \ttraining loss: 0.000938\n",
            "epoch: 60 \ttraining loss: 0.000899\n",
            "epoch: 61 \ttraining loss: 0.000879\n",
            "epoch: 62 \ttraining loss: 0.000869\n",
            "epoch: 63 \ttraining loss: 0.000818\n",
            "epoch: 64 \ttraining loss: 0.000804\n",
            "epoch: 65 \ttraining loss: 0.000795\n",
            "epoch: 66 \ttraining loss: 0.000775\n",
            "epoch: 67 \ttraining loss: 0.000752\n",
            "epoch: 68 \ttraining loss: 0.000726\n",
            "epoch: 69 \ttraining loss: 0.000696\n",
            "epoch: 70 \ttraining loss: 0.000695\n",
            "epoch: 71 \ttraining loss: 0.000670\n",
            "epoch: 72 \ttraining loss: 0.000655\n",
            "epoch: 73 \ttraining loss: 0.000648\n",
            "epoch: 74 \ttraining loss: 0.000622\n",
            "epoch: 75 \ttraining loss: 0.000604\n",
            "epoch: 76 \ttraining loss: 0.000595\n",
            "epoch: 77 \ttraining loss: 0.000587\n",
            "epoch: 78 \ttraining loss: 0.000570\n",
            "epoch: 79 \ttraining loss: 0.000564\n",
            "epoch: 80 \ttraining loss: 0.000552\n",
            "epoch: 81 \ttraining loss: 0.000547\n",
            "epoch: 82 \ttraining loss: 0.000535\n",
            "epoch: 83 \ttraining loss: 0.000521\n",
            "epoch: 84 \ttraining loss: 0.000507\n",
            "epoch: 85 \ttraining loss: 0.000523\n",
            "epoch: 86 \ttraining loss: 0.000499\n",
            "epoch: 87 \ttraining loss: 0.000479\n",
            "epoch: 88 \ttraining loss: 0.000480\n",
            "epoch: 89 \ttraining loss: 0.000458\n",
            "epoch: 90 \ttraining loss: 0.000455\n",
            "epoch: 91 \ttraining loss: 0.000447\n",
            "epoch: 92 \ttraining loss: 0.000437\n",
            "epoch: 93 \ttraining loss: 0.000430\n",
            "epoch: 94 \ttraining loss: 0.000432\n",
            "epoch: 95 \ttraining loss: 0.000413\n",
            "epoch: 96 \ttraining loss: 0.000418\n",
            "epoch: 97 \ttraining loss: 0.000396\n",
            "epoch: 98 \ttraining loss: 0.000393\n",
            "epoch: 99 \ttraining loss: 0.000398\n",
            "epoch: 100 \ttraining loss: 0.000394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in valid_loader:\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}%'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "153249c2-fa6d-4b0e-89b6-9570f1a669b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 97.43%\n"
          ]
        }
      ]
    }
  ]
}
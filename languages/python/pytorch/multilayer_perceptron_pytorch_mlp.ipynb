{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Multi-layer Perceptron (MLP)\n",
        "### This effort constructs a multi-layer perceptron neural model using the PyTorch machine learning library that is used for classificataion of the MNIST handwritten digit dataset."
      ],
      "metadata": {
        "id": "JZWFgSK_WyaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## construct model\n"
      ],
      "metadata": {
        "id": "tPoGEXrXKsId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "# define the model\n",
        "class MLPerceptron(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPerceptron, self).__init__()\n",
        "        input_size = 28 * 28\n",
        "        hidden_size = 128\n",
        "        output_size = 10\n",
        "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
        "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer3 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.layer4 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "        return x\n",
        "\n",
        "# create GPU device (if available)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# instantiate the model\n",
        "model = MLPerceptron() # multi-layer perceptron model\n",
        "\n",
        "# move the model to the GPU (if available)\n",
        "model.to(device)\n",
        "\n",
        "summary(model, (1, 28 * 28))\n",
        "\n",
        "# define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# download and load the data\n",
        "dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDcHRFbK2cQ0",
        "outputId": "8d1d84ae-3662-4ab8-cd8c-2043727862d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 128]         100,480\n",
            "            Linear-2               [-1, 1, 128]          16,512\n",
            "            Linear-3               [-1, 1, 128]          16,512\n",
            "            Linear-4                [-1, 1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 134,794\n",
            "Trainable params: 134,794\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.51\n",
            "Estimated Total Size (MB): 0.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model training"
      ],
      "metadata": {
        "id": "FlS55kuJYNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# number of epochs\n",
        "n_epochs = 30\n",
        "\n",
        "# split the dataset into training and validation sets\n",
        "training_size = int(0.8 * len(dataset))  # 80% for training\n",
        "validation_size = len(dataset) - training_size  # 20% for validation\n",
        "training_data, validation_data = random_split(dataset, [training_size, validation_size])\n",
        "\n",
        "# create training and validation data loaders\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "cXdB9qVrX9k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss criterion and optimizer\n",
        "loss_criterion = nn.MSELoss() # mean squared error loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=1.6) # stochaistic gradient descent\n",
        "\n",
        "print(\"training model\")\n",
        "\n",
        "# training and validation\n",
        "for epoch in range(n_epochs):\n",
        "    # training\n",
        "    model.train()\n",
        "    training_loss = 0.0\n",
        "    for inputs, labels in training_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # reshape the inputs and forward pass\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # transform labels to match the output shape\n",
        "        labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "\n",
        "        # calculate loss\n",
        "        loss = loss_criterion(outputs, labels)\n",
        "        training_loss += loss.item()\n",
        "\n",
        "        # backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # calculate average loss over an epoch\n",
        "    training_loss = training_loss / len(training_loader)\n",
        "\n",
        "    # validation loss\n",
        "    model.eval()\n",
        "    validation_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            # move inputs and labels to GPU (if available)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            inputs = inputs.view(inputs.shape[0], -1)\n",
        "            outputs = model(inputs)\n",
        "            labels = nn.functional.one_hot(labels, num_classes=10).float()\n",
        "            loss = loss_criterion(outputs, labels)\n",
        "            validation_loss += loss.item()\n",
        "    validation_loss = validation_loss / len(validation_loader)        \n",
        "\n",
        "    print('epoch: {} \\ttraining loss: {:.6f} \\tvalidation loss: {:.6f}'.format(epoch+1, training_loss, validation_loss))"
      ],
      "metadata": {
        "id": "hFdusGa4kXEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model validation"
      ],
      "metadata": {
        "id": "hDoTqpwdPgCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "error_inputs = []\n",
        "error_labels = []\n",
        "error_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # store inputs, labels, and predictions where predictions are incorrect\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != predicted[i]:\n",
        "                error_labels.append(label.item())\n",
        "                error_inputs.append(inputs[i])\n",
        "                error_predictions.append(predicted[i].item())\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}% ({:d} of {:d})'.format(accuracy, correct, total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSxNIaWKNwZ",
        "outputId": "0a0b5d44-5421-484b-c835-d8e712978a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 98.87% (11864 of 12000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot example of a failed prediction"
      ],
      "metadata": {
        "id": "mRWY4ykeWvrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "ind = 0\n",
        "input = error_inputs[ind]\n",
        "label = error_labels[ind]\n",
        "prediction = error_predictions[ind]\n",
        "\n",
        "print(input.size())\n",
        "\n",
        "# unnormalize and reshape the image\n",
        "image_tensor = (input * 0.5 + 0.5).reshape((28, 28))\n",
        "\n",
        "# convert to PIL Image\n",
        "image = to_pil_image(image_tensor)\n",
        "\n",
        "print(f'model prediction: {prediction} \\tlabel: {label}')\n",
        "\n",
        "# display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "hqORYRZdxbLv",
        "outputId": "108373cf-5648-45fc-ac16-91f5f1bcd4d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784])\n",
            "model prediction: 9 \tlabel: 3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g-SB_KXjeF5",
        "outputId": "8e9e4e25-9fd0-4d4b-913a-b53962d877ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## save the model weights and biases"
      ],
      "metadata": {
        "id": "34j18Ykp70OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, \"/content/gdrive/My Drive/model2305181601.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRe0msGk1CJy",
        "outputId": "bd7250bd-d58c-47ae-af74-b5867db7e06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load model parameters"
      ],
      "metadata": {
        "id": "FLcAc020i2xK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the mode\n",
        "model = MLPerceptron() # multi-layer perceptron model\n",
        "state_dict = torch.load(\"/content/gdrive/My Drive/model2305181601.pth\")\n",
        "model.load_state_dict(state_dict['model_state_dict'])\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0oiV3CIiIfK",
        "outputId": "ea0e907d-ad30-4bec-f073-01195e3dadee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPerceptron(\n",
              "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
              "  (layer4): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# validation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "error_inputs = []\n",
        "error_labels = []\n",
        "error_predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "        # move inputs and labels to GPU (if available)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        inputs = inputs.view(inputs.shape[0], -1)\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # get the predicted class for each sample in the batch\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        # count total number of labels and correct predictions\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # store inputs, labels, and predictions where predictions are incorrect\n",
        "        for i, label in enumerate(labels):\n",
        "            if label != predicted[i]:\n",
        "                error_labels.append(label.item())\n",
        "                error_inputs.append(inputs[i])\n",
        "                error_predictions.append(predicted[i].item())\n",
        "\n",
        "# calculate the percentage of correct predictions\n",
        "accuracy = correct / total * 100\n",
        "\n",
        "print('model accuracy: {:.2f}% ({:d} of {:d})'.format(accuracy, correct, total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrU6pKtrkIs0",
        "outputId": "f79ad98a-a799-4e4f-a8ec-457ad12bf437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model accuracy: 99.70% (11964 of 12000)\n"
          ]
        }
      ]
    }
  ]
}